{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "NR_UNIQUE_INPUTS = 10\n",
    "GRID_SIZE = 4\n",
    "VARIANCE = 0.1\n",
    "NR_CHANNELS = 3\n",
    "NR_INPUTS_PER_GROUND_TRUTH = 10\n",
    "\n",
    "def generate_checkerboard_samples(N, size):\n",
    "    # Initialize a tensor to hold the N samples of checkerboard patterns\n",
    "    samples = torch.zeros((N, size, size, 3))  # 3 for RGB channels\n",
    "\n",
    "    for i in range(N):\n",
    "        # Generate random colors for the checkerboard\n",
    "        color1 = torch.rand(3, dtype=torch.float32)  # Color for one set of squares\n",
    "        color2 = torch.rand(3, dtype=torch.float32)  # Color for the other set of squares\n",
    "\n",
    "        for x in range(size):\n",
    "            for y in range(size):\n",
    "                if (x + y) % 2 == 0:\n",
    "                    samples[i, x, y] = color1\n",
    "                else:\n",
    "                    samples[i, x, y] = color2\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "samples = generate_checkerboard_samples(2, GRID_SIZE)\n",
    "print(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(matrix : np.ndarray, title : str = \"\"):\n",
    "    plt.imshow(matrix, interpolation='none', vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "visualize(samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(input: np.ndarray, sigma : float) -> np.ndarray:\n",
    "\n",
    "    noisy_input = input + torch.randn(input.shape) * sigma\n",
    "    noisy_input = np.clip(noisy_input, 0, 1)\n",
    "\n",
    "    return noisy_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = generate_checkerboard_samples(NR_UNIQUE_INPUTS, GRID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(ground_truth):\n",
    "    grid_size = ground_truth.shape[1]\n",
    "\n",
    "    inputs = torch.empty(len(ground_truth) * NR_INPUTS_PER_GROUND_TRUTH, grid_size, grid_size, 3)\n",
    "    outputs = torch.empty(len(ground_truth) * NR_INPUTS_PER_GROUND_TRUTH, grid_size, grid_size, 3)\n",
    "\n",
    "    for i, no_noise_image in enumerate(ground_truth):\n",
    "        for j in range(NR_INPUTS_PER_GROUND_TRUTH):\n",
    "            inputs[i*NR_INPUTS_PER_GROUND_TRUTH + j] = add_noise(no_noise_image, VARIANCE)\n",
    "            outputs[i*NR_INPUTS_PER_GROUND_TRUTH + j] = no_noise_image # this may waste memory. Investigate if memory becomes an issue\n",
    "    \n",
    "    return inputs, outputs\n",
    "    \n",
    "dataset_inputs, dataset_outputs = generate_dataset(ground_truth)\n",
    "print(dataset_inputs.shape, dataset_inputs.shape)\n",
    "\n",
    "nr_inputs = len(dataset_inputs)\n",
    "\n",
    "sampled_numbers = np.random.choice(nr_inputs, size=min(2, len(dataset_inputs)), replace=False)\n",
    "# print(sampled_numbers)\n",
    "for i in sampled_numbers:\n",
    "    visualize(dataset_inputs[i])\n",
    "    visualize(dataset_outputs[i])\n",
    "\n",
    "straightened_inputs = dataset_inputs.view(nr_inputs, -1)\n",
    "straightened_outputs = dataset_outputs.view(nr_inputs, -1)\n",
    "\n",
    "print(straightened_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        # self.fc1 = nn.Linear(in_features=GRID_SIZE*GRID_SIZE*NR_CHANNELS, out_features=3*NR_CHANNELS)\n",
    "        # self.fc2 = nn.Linear(in_features=3*NR_CHANNELS, out_features=GRID_SIZE*GRID_SIZE*NR_CHANNELS)\n",
    "        self.fc1 = nn.Linear(in_features=GRID_SIZE*GRID_SIZE*NR_CHANNELS, out_features=GRID_SIZE*GRID_SIZE*NR_CHANNELS)\n",
    "        self.final_activation_fn = nn.Sigmoid()\n",
    "        # self.ReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        # output = self.fc2(output)\n",
    "        # output = self.ReLU(output)\n",
    "        output = self.final_activation_fn(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "model = DiffusionModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.03)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "cost_arr = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input_samples, ground_truth_samples in zip(straightened_inputs, straightened_outputs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_samples)\n",
    "\n",
    "        loss = criterion(outputs, ground_truth_samples)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], cost={running_loss}')\n",
    "    cost_arr.append(loss.item())\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ((1.0*my_loss[0])/loss_arr[0])**(-1)\n",
    "plt.plot(loss_arr, label='their loss')\n",
    "plt.plot([cur*x for cur in my_loss], label='my_loss', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def visualize_model_perf(idx):\n",
    "    input = straightened_inputs[idx]\n",
    "\n",
    "    output = model(input)\n",
    "\n",
    "    picture_output = output.view(GRID_SIZE, GRID_SIZE, NR_CHANNELS)\n",
    "    visualize(dataset_outputs[idx], \"ground_truth\")\n",
    "    visualize(input.view(GRID_SIZE, GRID_SIZE, NR_CHANNELS), \"noised input\")\n",
    "    visualize(picture_output.detach(), \"attempted denoise\")\n",
    "\n",
    "visualize_model_perf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
